---
title: "Breast Cancer Analysis"
output:
  word_document: default
  html_notebook: default
---
Importing the data for Breast cancer analysis
```{r}
#Loading the dataset in r
wisc_bc_df <- read.csv("C:/Users/Saurabh/Desktop/Home Work/ABI/data/wisc_bc_data.csv")

#Printing the structure of the dataset
str(wisc_bc_df)

```

Since there are a lot of variables we cant really tell which ones are redundant. Thus we keep all the variables as of now. Also after looking at the data we can say that the second variable appears to be the classification.

Now we Organize the data 

```{r}
#Printing the value counts of 'B;' and 'M' from the column
table(wisc_bc_df$diagnosis)

#Checking if there are na values in the diagnosis column of the dataframe
sum(is.na(wisc_bc_df$diagnosis))

#Renaming the labels pf the column from "B","M" to "benign","malugnant"
wisc_bc_df$diagnosis <- factor(wisc_bc_df$diagnosis, levels = c("B","M"), labels = c("benign","malignant"))

```

If we take a look at the data we get to know that not all the parameters are on the same scale of the measurement hence we need to transform all variables to comparable scales.

We here define a finction to normalize the values

```{r}

#defining the function and storing the function the variable normalize
normalize <- function(x){
  y <- (x-min(x))/(max(x)-min(x))
  y
}

#Applying Normalize function on columns 3 till 32 for all the rows
wbcd_n_L <- lapply(wisc_bc_df[ , 3:32], normalize)

#Converting the normalized datainto a dataframe and storing the dataframe in the variable wbcd_n
wbcd_n <- data.frame(wbcd_n_L)

#Printing the first 3 rows and first 4 columns of the dataframe we just normalzed
wbcd_n[1:3, 1:4]


#Adding id labels as rownames to keep a track of the patient's data 
rownames(wbcd_n) <- wisc_bc_df$id

#Isolating the class labels
BM_class <- wisc_bc_df[,2]

#Setting the name for each object as per ids
names(BM_class) <- wisc_bc_df$id

#Printing the first three rows of the inter list
BM_class[1:3]

```

Creating the training set and test validation datasets:

We need to split the data for training the model and for the verification of that model. A reasonabele balance is 2/3 for training and 1/3 for validation of the model we trained

```{r}
#Getting the count of the number of rows in the dataset
nrow(wisc_bc_df)

#Randomly shuffling the indexes of the dataset
rand_permute <- sample(x=1:569, size = 569)

#Prining the first 5 elements of the variable we just created
rand_permute[1:5]

#saving the random set of indexes so as to make sure each time we run it runs using the same random vakues as now
#save(rand_permute, file = 'rand_permute.RData')

#Used for reloading the random values
#load("rand_permute.RData")

#Storing the id column of the dataframe as per the indexes of the rendom number in the variable
all_id_random <- wisc_bc_df[rand_permute, "id"]

#Calculating 1/3rd of the data which comes around 189 which is the number we will be using for spliting the data
569/3
```

Now we split the data in to two groups one of those is training and the other one is for validation purpose

```{r}
#Converting all the Ids till 189 in to a character
validate_id <- as.character(all_id_random[1:189])

#Converting the remaining ids to character
training_id <- as.character(all_id_random[190:569])

#Storing the training data in the variable
wbcd_train <- wbcd_n[training_id,]

#Storing the validation data in the variable
wbcd_val <- wbcd_n[validate_id,]

#Storing the diagnosis for training data
BM_class_train <- BM_class[training_id]

#Storing the diagnosis for Validation data
BM_class_val <- BM_class[validate_id]

#Getting the count of tumour in training dataset
table(BM_class_train)

```

Loading package class since KNN algorithm is implemented in that package

```{r}
#Importing the package class so as to implement KNN
library(class)

```


In order to calculate K We calculate the square root of the Training set 

```{r}
#Calculating the square root of the training set
sqrt(nrow(wbcd_train))

#Thus we settle to a k value of 19
k <- 19

#Applying knn algorithm and storing the predicted results in variable
knn_predict <- knn(wbcd_train,wbcd_val,BM_class_train, k=19)

#Printing first 3 values of the predicted values
knn_predict[1:3]

#Checking actual values with predicted values
table(knn_predict,BM_class_val)

#Aligning the table with the probable values for every value=value/sumof values
prop.table(table(knn_predict, BM_class_val))

```

Testing the algorithm for different values of k

```{r}
#Verification for k=3,7,11,31
knn_predict_3 <- knn(wbcd_train, wbcd_val, BM_class_train, k = 3)
knn_predict_7 <- knn(wbcd_train, wbcd_val, BM_class_train, k = 7)
knn_predict_11 <- knn(wbcd_train, wbcd_val, BM_class_train, k = 11)
knn_predict_31 <- knn(wbcd_train, wbcd_val, BM_class_train, k = 31)

#Tabular format of actual vs predicted for 3,7,11,31
table(knn_predict_3,BM_class_val)
table(knn_predict_7,BM_class_val)
table(knn_predict_11,BM_class_val)
table(knn_predict_31,BM_class_val)


```


The best we could get was with k=3.

Improving the analysis

```{r}
#Printing the names of all the columns in the dataframe
names(wbcd_train)

#Applying linear regression on radius_mean against BM_class_train
lm_1 <- lm(radius_mean~BM_class_train, data = wbcd_train)

#Printing the summary of the model
summary(lm_1)

#Printing all the names of the columns in the dataframe 
names(summary(lm_1))

#Printing the fstatistic of the model
summary(lm_1)$fstatistic

#Printing the fstatistics value
summary(lm_1)$fstatistic[1]


```


In order to store the fstatistic value for all the 30 variables we need a vector

```{r}
#Creating a null numeric vector to store values for fstatistic for 30 variables
exp_var_fstat <- as.numeric(rep(NA, times=30))

#Assigning the names to the null vector as those of train dataframe
names(exp_var_fstat) <- names(wbcd_train)

#Storing the value of fstatistic in to the vector for radius_mean
exp_var_fstat["radius_mean"] <- summary(lm(radius_mean~BM_class_train, data=wbcd_train))$fstatistic[1]

#Storing the value of fstatistic in to the vector for texture_mean
exp_var_fstat["texture_mean"] <- summary(lm(texture_mean ~ BM_class_train, data = wbcd_train))$fstatistic[1]

#Storing the value of fstatistic in to the vector for perimeter_mean
exp_var_fstat["perimeter_mean"] <- summary(lm(perimeter_mean ~ BM_class_train, data = wbcd_train))$fstatistic[1]

#Printing the list to the console to check the values stored in it
exp_var_fstat

```

If we look above it seems cumbersome to calculate fstatistic for each and every variable instead we loop through variables and get the fstatistic value for all the variables.

```{r}
#Storing the names of the column in the variable
exp_vars <- names(wbcd_train)

#Storing numeric NA values in the variable
exp_var_fstat <- as.numeric(rep(NA,times=30))

#Setting the names of the object
names(exp_var_fstat) <- exp_vars

#for(j in 1:length(exp_vars)) {
  #Storing the value of fstatistic in vector
 # exp_var_fstat[exp_vars[j]] <- summary(lm(exp_vars[j]~BM_class_train,data=wbcd_train))$fstatistic[1]
#}

#modifying the formula and running the loop
for (j in 1:length(exp_vars)) {
 exp_var_fstat[exp_vars[j]] <-
 summary(lm(as.formula(paste(exp_vars[j], " ~ BM_class_train")),data = wbcd_train))$fstatistic[1]
}

#Printing the values of F statistics for each variable
exp_var_fstat


#Easier way of doing what is done above
exp_var_fstat2 <- sapply(exp_vars, function(x){
  summary(lm(as.formula(paste(x, "~BM_class_train")),data = wbcd_train))$fstatistic[1]
})

#Printing the values in the variable 
exp_var_fstat2

#Assigning names to the vector
names(exp_var_fstat2) <- exp_vars

#Stores a list of dataframes for a particular variable
wbcd_df_L <- lapply(exp_vars, function(x) {
 df <- data.frame(sample = rownames(wbcd_train), 
                  variable = x,
                  value = wbcd_train[,x],
                  class = BM_class_train)
 df
})

#Printing the head of the 
head(wbcd_df_L[[1]])

# Assigning names to the dataframe
names(wbcd_df_L) <- exp_vars


```
Using laply function from plyr library to get fstatistic value

```{r}
#importing the required libraries
library(plyr)

#applying linear regression on each df ans storing the values of those in a variable
var_sig_fstats <- laply(wbcd_df_L, function(df){
  fit <- lm(value~class, data=df)
  f <- summary(fit)$fstatistic[1]
  f
})

#Assigning the names to the variable
names(var_sig_fstats) <- names(wbcd_df_L)

#Printing the first 3 values from the list
var_sig_fstats[1:3]

#Storing the values according to descending value of fstatistics
most_sig_stats <- sort(var_sig_fstats, decreasing=T)

#Printing the first 5 values of the list
most_sig_stats[1:5]

#Printing the last 5 values of the list
most_sig_stats[25:30]
```

We can conclude from the above that the last variables in the list arent significant on their own. Adding them to the model will only increase the variance.

Thus we reorder the dataset as per the fstatistic values we found

```{r}
#Reordering the train dataframe
wbcd_train_ord <- wbcd_train[, names(most_sig_stats)]



```

Now since we have ordered the data as per the fstatistic value of the linear model, the next step is to access how many variables we shoukd consider to give the best fit hence we perform cross validation


Further now we divide the training set into size 2/3
```{r}
#Printing the length of the training_id
length(training_id)

#Printing 2/3rd of the length
(2/3) * length(training_id)

#subtracting 253 from length of the ids
length(training_id)-253

#creating 1000 samples of random 253 values from set and storing it in the variable
training_family_L <- lapply(1:1000, function(j) {
 perm <- sample(1:380, size = 380, replace = F)
 shuffle <- training_id[perm]
 trn <- shuffle[1:253]
 trn
})

#Saving the randomvalues we just generated
#save(training_family_L, file='training_family_L.RData')

#Loading the values
#load("training_family_L.RData")

#Creating Validation set for each training set
validation_family_L <- lapply(training_family_L,function(x)
  setdiff(training_id,x))

```

We are all set with the requirements and will now find the optimal set of variables and optimal value for k


```{r}
#Creating a sequence for variables values from 3 to 29 with stepsize of 2
N <- seq(from = 3, to=29, by=2)

#Finding the square root of the length of the dataframe
sqrt(length(training_family_L[[1]]))

#We will vary our k from 3 to 19
K <- seq(from=3 , to=19, by=2)

#Number of choices we will validate for KNN
1000*length(N)*length(K)
```


```{r}

#Creating a dataframe for errors
paramter_errors_df <- data.frame(mc_index = as.integer(rep(NA,times = 126000)), 
                                 var_num = as.integer(rep(NA, times = 126000)), 
                                 k =as.integer(rep(NA, times = 126000)),
                                 error = as.numeric(rep(NA, times = 126000)))

#Writing test for the first 5 variables we found according to fstatistics and with k=7
knn_test <- knn(train = wbcd_train_ord[training_family_L[[1]],1:5], 
                test = wbcd_train_ord[validation_family_L[[1]], 1:5], 
                cl = BM_class_train[training_family_L[[1]]], k = 7)

#Printing the first 3 values of the test we ran above
knn_test[1:3]

#Storing acutal vs predicted in variable tbl_test
tbl_test <- table(knn_test,BM_class_train[validation_family_L[[1]]])

#Printing the result
tbl_test

#Calculating total error and dividing it with the total length of the Validation family
err_rate <- (tbl_test[1, 2] + tbl_test[2,1])/length(validation_family_L[[1]])
err_rate

```

```{r}
# j = index, n = length of range of variables, k=k
# Creating a function for j,n,k
core_knn <- function(j, n, k) {
 knn_predict <- knn(train =wbcd_train_ord[training_family_L[[j]], 1:n],
                    test = wbcd_train_ord[validation_family_L[[j]], 1:n],
                    cl=BM_class_train[training_family_L[[j]]],
                    k = k)
 tbl <- table(knn_predict,BM_class_train[validation_family_L[[j]]])
 err <- (tbl[1, 2] + tbl[2, 1])/length(validation_family_L[[j]])
 err
}

#Running a sample on the function we just created
core_knn(1, 5, 7)
```




```{r}
#to keep the track of what loop we are in
iter <- 1

#Storing start time of the system
str_time <- Sys.time()

#Looping for all 126000 values of combinations
for (j in 1:1000) {
 for (n in 1:length(N)) {
   for (m in 1:length(K)) {
     err <- core_knn(j, N[n], K[m])
     paramter_errors_df[iter, ] <- c(j, N[n], K[m], err)
     iter <- iter + 1
    }
  }
}
#Calculating total time required for running the loop
time_lapsed_for <- Sys.time() - str_time

#Saving the paramter for errors
save(paramter_errors_df, time_lapsed_for, file ="for_loop_paramter_errors.RData")

#Loading the parameter
load("for_loop_paramter_errors.RData")

#Printing the time for which the loop was running
time_lapsed_for

#Merging combination of 1000 random draws with number of variables
param_df1 <- merge(data.frame(mc_index = 1:1000),data.frame(var_num = N))

#Merging the above combination with k values
param_df <- merge(param_df1, data.frame(k = K))

#We get combination of all the values
str(param_df)


#For first 20 values
knn_err_est_df_test <- ddply(param_df[1:20, ], .(mc_index, var_num,k), function(df) {
 err <- core_knn(df$mc_index[1], df$var_num[1], df$k[1])
 err
})
#Printing head of the error values
head(knn_err_est_df_test)

#Storing the start time
str_time <- Sys.time()

#Applying KNN for calculating error
knn_err_est_df <- ddply(param_df, .(mc_index, var_num, k), function(df) {
 err <- core_knn(df$mc_index[1], df$var_num[1], df$k[1])
 err
})

#Calculating the lapsed time
time_lapsed <- Sys.time() - str_time

#Storing the lapsed time
save(knn_err_est_df, time_lapsed, file = "knn_err_est_df.RData")

#Loading the Time lapsed
load("knn_err_est_df.RData")

#Printing the time lapsed on the console
time_lapsed

#Printing the head of the KNN Error Estimate
head(knn_err_est_df)

#Renaming column 4 to Error
names(knn_err_est_df)[4] <- "error"

```


Now we will Get the summary performance of the statistics

```{r}
#Creating subset with var num 5 and 7
mean_ex_df <- subset(knn_err_est_df, var_num == 5 & k == 7)

#Printing head of the dataframe
head(mean_ex_df)

#Calculating mean error
mean(mean_ex_df$error)

#Calculating errors for all the number of parameters and k values
mean_errs_df <- ddply(knn_err_est_df, .(var_num, k), function(df)mean(df$error))

#Printing the head of the vector
head(mean_errs_df)

#Renaming the last column to mean_error
names(mean_errs_df)[3] <- "mean_error"
```


Visualizing all the parameters performances

```{r}
#importing the required libraries
library(ggplot2)

#Plotting var_num against k as per mean_error 
ggplot(data = mean_errs_df, aes(x = var_num, y = k, color = mean_error))+ geom_point(size = 10) + theme_bw()

#Plotting the same plot as above for k values from 15 to 29
ggplot(data = subset(mean_errs_df, var_num >= 15), aes(x = var_num,y = k, color = mean_error)) + geom_point(size = 10) + theme_bw()

```

After looking at the plots we figure that with 19 variables and low k value the algorithm seems to work best.
Thus we explore the mean_error of variables 17,19,21,25.

```{r}
#Extracting subset with first 17 variable  for all the k values which shows mean_error
subset(mean_errs_df, var_num == 17)

#Extracting subset with first 19 variable  for all the k values which shows mean_error
subset(mean_errs_df, var_num == 19)

#Extracting subset with first 21 variable  for all the k values which shows mean_error
subset(mean_errs_df, var_num == 21)

#Extracting subset with first 25 variable  for all the k values which shows mean_error
subset(mean_errs_df, var_num == 25)

#Printing the row with minimum mean error value
mean_errs_df[which.min(mean_errs_df$mean_error), ]
```

By looking at the above data we can infer that the best is with 27 variables with k=3.

```{r}
#Printing the variables name to the console as per their fstatistics value
names(wbcd_train_ord)
```


Validation of the final test 

```{r}
#Sorting the variables as per how we arranged the data above
wbcd_val_ord <- wbcd_val[, names(wbcd_train_ord)]

#Applying knn algorithm for optimal values of varables and k which we found to be 27 and 3 respectively to predict the validation set
bm_val_pred <- knn(train = wbcd_train_ord[, 1:27], wbcd_val_ord[,1:27], BM_class_train, k = 3)

#Storing predicted values and actual values for validation set in tabular format
tbl_bm_val <- table(bm_val_pred, BM_class_val)

#Printing the above table to console
tbl_bm_val

#Calculating standard error which is summation of error values divided by total number of values
(val_error <- tbl_bm_val[1, 2] + tbl_bm_val[2,1])/length(BM_class_val)



```


Speeding up the KNN algorithm

```{r}

#Installing the required packages
#install.packages("doParallel")
#install.packages("doSNOW")

#Importing the required libraries
library(doParallel)
library(doSNOW)

#register the parallel backend with the foreach package  
registerDoParallel()

#Printing the number of cores we are using
getDoParWorkers()

#Storing sys.time
str_time <- Sys.time()

#Running knn test parallely on the number of cores we found above
knn_err_est_df_par <- ddply(param_df, .(mc_index, var_num, k),
function(df) {
 err <- core_knn(df$mc_index[1], df$var_num[1], df$k[1])
 err
}, .parallel = T)

#Storing the time lapsed i.e time for actual run
time_lapsed_par <- Sys.time() - str_time

#Saving the value of the run
save(knn_err_est_df_par, time_lapsed_par, file ="knn_err_est_df_par.RData")
```











